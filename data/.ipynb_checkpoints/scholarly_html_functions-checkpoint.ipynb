{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process a object that contains information about a person\n",
    "def process_people_group(people_group_els, this_ref_dict):\n",
    "    \n",
    "    #scroll through the people objects\n",
    "    for pg_els in people_group_els:\n",
    "        \n",
    "        #define the person dictionary\n",
    "        person_dict = {}\n",
    "        \n",
    "        #run through the elements in this person object\n",
    "        for span_el in pg_els:\n",
    "            \n",
    "            #print(span_el)\n",
    "            \n",
    "            #check if we have reached the et al.\n",
    "            if span_el.name == 'i':\n",
    "                person_dict['etal'] = 'etal'\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            #store the person's details\n",
    "            person_dict[span_el['class'][0]] = span_el.text\n",
    "\n",
    "        #store this person\n",
    "        this_ref_dict['people'].append(person_dict)\n",
    "        \n",
    "    return this_ref_dict\n",
    "\n",
    "#process an list element which is a reference\n",
    "def process_reference_element(l):\n",
    "    \n",
    "    #set up the empty reference dictionary to be safe\n",
    "    ref_dict = {}\n",
    "    \n",
    "    #run through the elements of this reference element\n",
    "    for t in l.children:\n",
    "\n",
    "        #check if the item is whatever a navigable string is\n",
    "        if 'bs4.element.NavigableString' in str(t.__class__):\n",
    "            #move on if it does\n",
    "            continue\n",
    "\n",
    "        #if we have the label element grab it and form the background of our element\n",
    "        if t.name == 'a':\n",
    "            ref_dict = {'people':[],\n",
    "                       'label':t['name'],\n",
    "                       'ref_no':int(t['name'][1:])}\n",
    "            continue\n",
    "\n",
    "        #go through the children of the reference to grab the reference's elements\n",
    "        for u in t.children:\n",
    "            \n",
    "            #check that the element we have is not a NavigableString\n",
    "            if 'bs4.element.NavigableString' in str(u.__class__):\n",
    "                #move on if it does\n",
    "                continue\n",
    "\n",
    "            #if we have a person group then we want to use our extraction tool\n",
    "            if 'person-group' in u['class'][0]:\n",
    "\n",
    "                #process it as a people element\n",
    "                ref_dict = process_people_group(u, ref_dict)\n",
    "\n",
    "            else: \n",
    "                \n",
    "                #find to see if there are links in here\n",
    "                As = u.findAll('a')\n",
    "                \n",
    "                #if there are links we process it as a link object\n",
    "                if As != []:\n",
    "\n",
    "                    #if we have a reference link we store the text as well\n",
    "                    #as the link\n",
    "                    ref_dict[u['class'][0]] = {'link':As[0]['href'],\n",
    "                                               'text':u.text}\n",
    "\n",
    "                else:\n",
    "                    #we have a plain piece of information, lets just store it\n",
    "                    ref_dict[u['class'][0]] = u.text\n",
    "    \n",
    "    \n",
    "    return ref_dict\n",
    "\n",
    "#this is the function for extracting the references from the tail\n",
    "def extract_references(tail):\n",
    "    \n",
    "    references = []\n",
    "\n",
    "    #find the references block\n",
    "    refs = tail.find('div', {'tag':'ref-list'})\n",
    "\n",
    "    #find the references list\n",
    "    r = refs.find('ul')\n",
    "\n",
    "    #go through the list of references\n",
    "    for ref_el in r.children:\n",
    "\n",
    "        #check if the item is whatever a navigable string is\n",
    "        if 'bs4.element.NavigableString' in str(ref_el.__class__):\n",
    "            #move on if it does\n",
    "            continue\n",
    "\n",
    "        ref_dict = process_reference_element(ref_el)\n",
    "        \n",
    "        if ref_dict != {}:\n",
    "            references.append(ref_dict)\n",
    "        \n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#define a class to extract the acknowledgments\n",
    "class acknowledgements_extractor(object):\n",
    "    \n",
    "    def __init__(self, tail):\n",
    "        \n",
    "        #get the acknowledgements element\n",
    "        acks = tail.find('div', {'class':'ack'})\n",
    "\n",
    "        #get the ack_dict element\n",
    "        self.ack_dict = {'text':''}\n",
    "        \n",
    "        #start iterating\n",
    "        self.iteracks(acks)\n",
    "        \n",
    "    def iteracks(self, el):\n",
    "                \n",
    "        #iterate through the children of this device\n",
    "        for child in el.children:\n",
    "            \n",
    "            #check if the item is whatever a navigable string is\n",
    "            if 'bs4.element.NavigableString' in str(child.__class__):\n",
    "                #move on if it does\n",
    "                continue\n",
    "            \n",
    "            #check if we have an div, usually the acknowledgments heading\n",
    "            if child.name == 'div':\n",
    "\n",
    "                #check if this element is a title\n",
    "                if child['class'][0] == 'title':\n",
    "\n",
    "                    self.ack_dict['title'] = child.text.strip()\n",
    "                    \n",
    "                    #if it is we are done with this element\n",
    "                    continue\n",
    "                    \n",
    "                #go one level down\n",
    "                self.iteracks(child)\n",
    "            \n",
    "            #check if this is a text element\n",
    "            elif child.name == 'p':\n",
    "                \n",
    "                #now we need to extract and store the result\n",
    "                self.ack_dict['text'] += ' ' + el.text.strip()\n",
    "\n",
    "\n",
    "#this is the object that will process the paper and in which the results will be stored\n",
    "class paper_obj(object):\n",
    "    \n",
    "    def __init__(self, html_file, keep_fig_caps = True):\n",
    "        \n",
    "        \n",
    "        self.abstract_text = ''\n",
    "        self.body_text = ''\n",
    "        self.title = ''\n",
    "        \n",
    "        self.figures = []\n",
    "        \n",
    "        self.authors = []\n",
    "        \n",
    "        self.abstract_el = False\n",
    "        self.body_el = False\n",
    "        \n",
    "        #tell the tool to keep the figure captions in the fulltexts\n",
    "        self.keep_fig_labels = keep_fig_caps\n",
    "        \n",
    "        #load the data in\n",
    "        with open(html_file, 'r') as f:\n",
    "\n",
    "            raw_text = f.read()\n",
    "            \n",
    "            \n",
    "        #parse the html into soup\n",
    "        soup = BeautifulSoup(raw_text, 'html.parser')\n",
    "\n",
    "        #extract the metadata\n",
    "        front = soup.find('div', {'class':'front'})\n",
    "        \n",
    "        #extract the body\n",
    "        body = soup.find('div', {'class':'body'})\n",
    "        \n",
    "        #extract the tail\n",
    "        tail = soup.find('div', {'class':'back'})\n",
    "        \n",
    "        #extract the metadata into a json\n",
    "        self.meta = self.iterhtml(front)\n",
    "        \n",
    "        #we are now going to work with the body so set the flag\n",
    "        self.body_el = True\n",
    "        \n",
    "        #extract the body of the document\n",
    "        self.body = self.iterhtml(body)\n",
    "        \n",
    "        #we are done with the body so we will reset the body to False\n",
    "        self.body_el = False\n",
    "        \n",
    "        \n",
    "        #extract the end notes\n",
    "        self.extract_tail(tail)\n",
    "\n",
    "    def iterhtml(self, el):\n",
    "        \n",
    "        #set up the json we're going to be returning\n",
    "        store_json = {}\n",
    "        \n",
    "        #check if this item has children\n",
    "        if el.children:\n",
    "\n",
    "            for item in el.children:\n",
    "\n",
    "                #check if the item is whatever a navigable string is\n",
    "                if 'bs4.element.NavigableString' in str(item.__class__):\n",
    "                    #move on if it does\n",
    "                    continue\n",
    "\n",
    "                if item.name == 'div':\n",
    "\n",
    "                    #object_name = item.text\n",
    "\n",
    "                    #check if we have a title object\n",
    "                    if item.has_attr('tagx'):\n",
    "\n",
    "                        if item['tagx'] == 'title':\n",
    "                            store_json['title'] = item.text.strip()\n",
    "\n",
    "                            #this is a heading, lets store the text from it\n",
    "                            self.capture_text(item)\n",
    "                            \n",
    "                            #this is not a div element we are interested in diving into\n",
    "                            #so lets move on\n",
    "                            continue\n",
    "                            \n",
    "                    if item['class'][0] == 'fig':\n",
    "                        \n",
    "                        self.process_figure(item)\n",
    "                        \n",
    "                        #we dont want to dive in here since that will lead to double counts.\n",
    "                        #lets move on\n",
    "                        continue\n",
    "                        \n",
    "                    elif item['class'][0] == 'abstract':\n",
    "                        \n",
    "                        #this is going to be the abstract and we want to extract\n",
    "                        #the text from it so lets use this function here to do that\n",
    "                        self.process_abstract(item)\n",
    "                        \n",
    "                        #we are done here so lets move on since the diving in happened in\n",
    "                        #the process abstract function\n",
    "                        #continue\n",
    "                    \n",
    "                    #we have the title of the article\n",
    "                    elif item['class'][0] == 'article-title':\n",
    "                        \n",
    "                        #store the title since the title is a unique class all of its own\n",
    "                        store_json[item['class'][0]] = item.text.strip()\n",
    "                        \n",
    "                        self.title = item.text.strip()\n",
    "                        \n",
    "                        #this will not go any deeper so lets move on\n",
    "                        continue\n",
    "                        \n",
    "                    #we have the authors information\n",
    "                    elif item['class'][0] == 'contrib-group':\n",
    "                        \n",
    "                        #extract the authors from our author element\n",
    "                        self.process_authors(item)\n",
    "                        \n",
    "                        #now move on since we're done with this element\n",
    "                        continue\n",
    "                        \n",
    "                    #do some recursion\n",
    "                    store_json[item['class'][0]] = self.iterhtml(item)\n",
    "                    \n",
    "                    #we dont want to store text from div elements so lets move on\n",
    "                    #continue\n",
    "\n",
    "                #we have a span object which contains information we are interested in\n",
    "                elif item.name == 'span':\n",
    "                    \n",
    "                    #check if there is a link in this item\n",
    "                    \n",
    "                    links = item.findAll('a')\n",
    "                    \n",
    "                    if len(links) > 0:\n",
    "                        \n",
    "                        #\n",
    "                        store_json[item['class'][0]] = {'text':item.text.strip(),\n",
    "                                                       'links':[]}\n",
    "                        \n",
    "                        #go through this links we have in this span element\n",
    "                        for link in links:\n",
    "                            \n",
    "                            store_json[item['class'][0]]['links'].append({'link':link['href'],\n",
    "                                                                         'text':link.text.strip()})\n",
    "                            \n",
    "                    else:\n",
    "                        #just store the text from the item\n",
    "                        store_json[item['class'][0]] = item.text.strip()\n",
    "                    \n",
    "                    #grab the text from this element\n",
    "                    self.capture_text(item)\n",
    "                \n",
    "                #if we have a list of the element\n",
    "                elif item.name == 'p':\n",
    "                    \n",
    "                        \n",
    "                    if 'text' not in store_json.keys():\n",
    "\n",
    "                        store_json['text'] = ''\n",
    "\n",
    "                    store_json['text'] += item.text\n",
    "                    \n",
    "                    #grab the text from this element\n",
    "                    self.capture_text(item)\n",
    "                 \n",
    "        return store_json\n",
    "    \n",
    "    def capture_text(self, el):\n",
    "        \n",
    "        #check if we are working with a body\n",
    "        if self.body_el:\n",
    "            self.body_text += el.text + '\\n'\n",
    "\n",
    "        #if we have an abstract element we want to store it\n",
    "        elif self.abstract_el:\n",
    "            self.abstract_text += el.text + '\\n'\n",
    "            \n",
    "    def process_figure(self, fig_el):\n",
    "        \n",
    "        fig_dict = {'caption':''}\n",
    "\n",
    "        for child in fig_el.children:\n",
    "\n",
    "            #check if the item is whatever a navigable string is\n",
    "            if 'bs4.element.NavigableString' in str(child.__class__):\n",
    "                #move on if it does\n",
    "                continue\n",
    "\n",
    "            if child.name == 'div':\n",
    "\n",
    "                fig_dict['title'] = child.text\n",
    "                \n",
    "                if self.keep_fig_labels:\n",
    "                    self.capture_text(child)\n",
    "\n",
    "            elif child.name == 'p':\n",
    "                #child.name == 'p':\n",
    "                \n",
    "                if self.keep_fig_labels:\n",
    "                    self.capture_text(child)\n",
    "\n",
    "                fig_dict['caption'] += child.text + '\\n'\n",
    "        \n",
    "        #store the title and caption for this figure\n",
    "        fig_dict['title'] = fig_dict['title'].strip()\n",
    "        fig_dict['caption'] = fig_dict['caption'].strip()\n",
    "        \n",
    "        #store the details of this figure\n",
    "        self.figures.append(fig_dict)\n",
    "\n",
    "\n",
    "    def extract_tail(self, tail):\n",
    "        \n",
    "        ack_tool = acknowledgements_extractor(tail)\n",
    "        \n",
    "        self.acknowledgements = ack_tool.ack_dict\n",
    "        \n",
    "        self.references = extract_references(tail)\n",
    "    \n",
    "    \n",
    "    def process_abstract(self, el):\n",
    "        \n",
    "        self.abstract_el = True\n",
    "        \n",
    "        self.iterhtml(el)\n",
    "        \n",
    "        self.abstract_el = False\n",
    "    \n",
    "    #process the list of authors\n",
    "    def process_authors(self, el):\n",
    "        \n",
    "        #extract a list of author elements\n",
    "        raw_authors = el.findAll('span', {'class':'contrib'})\n",
    "    \n",
    "        #move through the authors and extract them\n",
    "        for author in raw_authors:\n",
    "            \n",
    "            #extract the details of this author\n",
    "            author_dict = {}\n",
    "            for stat in author.children:\n",
    "\n",
    "\n",
    "                #if we have the person's link\n",
    "                if stat.name == 'a':\n",
    "\n",
    "                    author_dict['link'] = {'link':stat['href'],\n",
    "                                          'text':stat.text.strip()}\n",
    "\n",
    "                    continue\n",
    "\n",
    "                #extract the name information if we are looking at the name element\n",
    "                if stat['class'][0] == 'name':\n",
    "\n",
    "                    for nam in stat.children:\n",
    "\n",
    "                        author_dict[nam['class'][0]] = nam.text\n",
    "                        \n",
    "                #extract the other information if we have a non-name piece of info, e.g. email address\n",
    "                else:\n",
    "\n",
    "                    author_dict[stat['class'][0]] = stat.text.strip()\n",
    "\n",
    "            #store what we've extracted about this author\n",
    "            self.authors.append(author_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Background\n",
      "The key enzymes of photosynthetic carbon assimilation in C4 plants have evolved independently several times from C3 isoforms that were present in the C3 ancestral species. The C4 isoform of phosphoenolpyruvate carboxylase (PEPC), the primary CO2-fixing enzyme of the C4 cycle, is specifically expressed at high levels in mesophyll cells of the leaves of C4 species. We are interested in understanding the molecular changes that are responsible for the evolution of this C4-characteristic PEPC expression pattern, and we are using the genus Flaveria (Asteraceae) as a model system. It is known that cis-regulatory sequences for mesophyll-specific expression of the ppcA1 gene of F. trinervia (C4) are located within a distal promoter region (DR).\n",
      "\n",
      "Results\n",
      "In this study we focus on the proximal region (PR) of the ppcA1 promoter of F. trinervia and present an analysis of its function in establishing a C4-specific expression pattern. We demonstrate that the PR harbours cis-regulatory determinants which account for high levels of PEPC expression in the leaf. Our results further suggest that an intron in the 5' untranslated leader region of the PR is not essential for the control of ppcA1 gene expression.\n",
      "\n",
      "Conclusion\n",
      "The allocation of cis-regulatory elements for enhanced expression levels to the proximal region of the ppcA1 promoter provides further insight into the regulation of PEPC expression in C4 leaves.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the filename\n",
    "filename = './results/PMC2241601/scholarly.html'\n",
    "\n",
    "#create the paper object\n",
    "result = paper_obj(filename)\n",
    "\n",
    "print(result.abstract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calmodulin (CaM) is involved in defense responses in plants. In soybean (Glycine max), transcription of calmodulin isoform 4 (GmCaM4) is rapidly induced within 30 min after pathogen stimulation, but regulation of the GmCaM4 gene in response to pathogen is poorly understood. Here, we used the yeast one-hybrid system to isolate two cDNA clones encoding proteins that bind to a 30-nt A/T-rich sequence in the GmCaM4 promoter, a region that contains two repeats of a conserved homeodomain binding site, ATTA. The two proteins, GmZF-HD1 and GmZF-HD2, belong to the zinc finger homeodomain (ZF-HD) transcription factor family. Domain deletion analysis showed that a homeodomain motif can bind to the 30-nt GmCaM4 promoter sequence, whereas the two zinc finger domains cannot. Critically, the formation of super-shifted complexes by an anti-GmZF-HD1 antibody incubated with nuclear extracts from pathogen-treated cells suggests that the interaction between GmZF-HD1 and two homeodomain binding site repeats is regulated by pathogen stimulation. Finally, a transient expression assay with Arabidopsis protoplasts confirmed that GmZF-HD1 can activate the expression of GmCaM4 by specifically interacting with the two repeats. These results suggest that the GmZF-HD1 and –2 proteins function as ZF-HD transcription factors to activate GmCaM4 gene expression in response to pathogen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './results/PMC1920248/scholarly.html'\n",
    "\n",
    "#create the paper object\n",
    "paper = paper_obj(filename)\n",
    "\n",
    "print(paper.abstract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
